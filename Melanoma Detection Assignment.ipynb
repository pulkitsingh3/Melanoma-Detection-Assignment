{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1RKexZtRZ5Gsr-UlLJwkqb1shnlnkza4H","authorship_tag":"ABX9TyPnj8ZgDocgs95+w5vGBosc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Problem statement: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."],"metadata":{"id":"bak65QfqUji7"}},{"cell_type":"markdown","source":["#### Importing all the important libraries"],"metadata":{"id":"O_7j9JU4UYcE"}},{"cell_type":"code","source":["import pathlib\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import os\n","import PIL\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential"],"metadata":{"id":"aAOAiEK3U4sD","executionInfo":{"status":"ok","timestamp":1663165987973,"user_tz":-330,"elapsed":653,"user":{"displayName":"pulkit singh parihar","userId":"01517847143384874755"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["**1. Data Reading/Data Understanding**"],"metadata":{"id":"SrgHH5ra2U9A"}},{"cell_type":"code","source":["from zipfile import ZipFile\n","with ZipFile('drive/MyDrive/CNN_assignment.zip', 'r') as zipobj:\n","  zipobj.extractall('drive/MyDrive/CNN_assignment')"],"metadata":{"id":"s6pdvSrTmuey"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Mounting the google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","## Ref:https://drive.google.com/file/d/1Dy6A-76u4Aa1Sti40pDpl4qbP2gr1u_v/view?usp=sharing"],"metadata":{"id":"n5Y4StAbVDFi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Path for train and test images\n","data_dir_train = pathlib.Path(\"/content/drive/MyDrive/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\n","data_dir_test = pathlib.Path('/content/drive/MyDrive/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Test')"],"metadata":{"id":"DQUki2ALVhlR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n","print(image_count_train)\n","image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n","print(image_count_test)"],"metadata":{"id":"EgehGslMVv6y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2. Dataset Creation**\n","\n","Create train & validation dataset from the train directory with a batch size of 32. Also, make sure you resize your images to 180*180"],"metadata":{"id":"Wv50yc6N2hap"}},{"cell_type":"code","source":["batch_size = 32\n","img_height = 180\n","img_width = 180"],"metadata":{"id":"_X5e5KIn2dzQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Create train dataset from the train directory\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    data_dir_train,\n","    seed=123,\n","    validation_split= 0.2,\n","    subset= 'training',\n","    image_size=(img_height,img_width),\n","    batch_size = batch_size\n",")"],"metadata":{"id":"3yKRBKKz2zkg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Create validation dataset from the train directory \n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    data_dir_train,\n","    seed=123,\n","    validation_split= 0.2,\n","    subset= 'validation',\n","    image_size=(img_height,img_width),\n","    batch_size = batch_size\n",")"],"metadata":{"id":"98TUjcqI4D__"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# List out all the classes of skin cancer and store them in a list. \n","class_names = train_ds.class_names\n","print(class_names)"],"metadata":{"id":"Nd_9z-Mi4W7u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3. Dataset visualisation**\n","\n","Create a code to visualize one instance of all the nine classes present in the dataset \n"],"metadata":{"id":"VGwRO2D_4qAH"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.figure(figsize=(10,10))\n","for i in range(9): \n","  plt.subplot(3, 3, i + 1)\n","  image = plt.imread(str(list(data_dir_train.glob(class_names[i]+'/*.jpg'))[1]))\n","  plt.title(class_names[i])\n","  plt.imshow(image)"],"metadata":{"id":"2W1TsNVI4jk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Dataset.cache() keeps the images in memory after they're loaded off disk during the first epoch.\n","## Dataset.prefetch() overlaps data preprocessing and model execution while training.\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"aPCUScjL5CgG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**4.Model Building & training**\n","\n","Create a CNN model, which can accurately detect 9 classes present in the dataset. While building the model, rescale images to normalize pixel values between (0,1)."],"metadata":{"id":"F2vEnR655l2X"}},{"cell_type":"code","source":["from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","num_classes = 9\n","model = Sequential([\n","                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n","])\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu', input_shape = (180, 180, 32)))\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","\n","model.add(Flatten())\n","model.add(Dense(num_classes, activation = \"softmax\"))"],"metadata":{"id":"A6N4VV-z5gSM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compile the model"],"metadata":{"id":"Gri6QPZv7VG4"}},{"cell_type":"code","source":["### Choose an appropirate optimiser and loss function\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"metadata":{"id":"Fxx7Zmu97VlW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# View the summary of all layers\n","model.summary()"],"metadata":{"id":"871moqwe7agm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train the model"],"metadata":{"id":"NBc4-50F7jWC"}},{"cell_type":"code","source":["## Train the model for ~20 epochs\n","epochs = 20\n","history = model.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs\n",")"],"metadata":{"id":"eAV6Gfet7h5W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Findings after the model fit. Check any evidence of model overfit or underfit."],"metadata":{"id":"icHwtb4Dh7Oq"}},{"cell_type":"code","source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"metadata":{"id":"1p9FQEjX7oj5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["****Finding on the first base model****\n","-  The model is overfitting because we can see difference in loss functions in training and validation.\n","-  The difference in accuracy of training and validation data is large enough which showes overfitting of model."],"metadata":{"id":"oS9JqsoIiOTC"}},{"cell_type":"markdown","source":["**5. Chose an appropriate data augmentation strategy to resolve overfitting**"],"metadata":{"id":"vA_HK3yzh5lM"}},{"cell_type":"code","source":["## Choose an appropriate data augumentation strategy\n","data_augument = keras.Sequential([\n","                             layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\",input_shape=(img_height,img_width,3)),\n","                             layers.experimental.preprocessing.RandomRotation(0.2, fill_mode='reflect'),\n","                             layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3), fill_mode='reflect')\n","])"],"metadata":{"id":"OYMauml2jtCF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Visualize the augmentation strategy for one instance of training image.\n","plt.figure(figsize=(12, 12))\n","for images, labels in train_ds.take(1):\n","    for i in range(9):\n","        ax = plt.subplot(3, 3, i + 1)\n","        plt.imshow(data_augument(images)[i].numpy().astype(\"uint8\"))\n","        plt.title(class_names[labels[i]])\n","        plt.axis(\"off\")"],"metadata":{"id":"yC9SgCWTj-CV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**6. Model Building & training on the augmented data**\n","\n","Create a CNN model, which can accurately detect 9 classes present in the dataset. While building the model rescale images to normalize pixel values between (0,1)."],"metadata":{"id":"1i4Gw_F6kgEb"}},{"cell_type":"code","source":["## Dropout layer if there is an evidence of overfitting in our findings\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","num_classes = 9\n","model = Sequential([ data_augument,\n","                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n","      \n","])\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu', input_shape = (180, 180, 32)))\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","\n","model.add(Flatten())\n","model.add(Dense(num_classes, activation = \"softmax\"))"],"metadata":{"id":"qWqOuKjKkj3N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compiling the model"],"metadata":{"id":"_yVqbEFykvHf"}},{"cell_type":"code","source":["## Choose an appropriate optimiser and loss function for model training\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"metadata":{"id":"hY5ShFUBkr9u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training the model"],"metadata":{"id":"ut4qBnAfllrN"}},{"cell_type":"code","source":["## Train the model for ~20 epochs\n","epochs=20\n","history = model.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs\n",")"],"metadata":{"id":"wFoVCGitk1ad"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["****Finding from Second Model****"],"metadata":{"id":"4XK7M17_3E_M"}},{"cell_type":"markdown","source":["-  There is no improvement in accuracy but we can definitely see the overfitting problem has solved due to data augmentation.\n","-  We can increase the epochs to increase the accuracy so it's too early for judgement.\n"],"metadata":{"id":"9xhkBXhf3N97"}},{"cell_type":"code","source":["## See the images based on their labels\n","path_list=[]\n","lesion_list=[]\n","for i in class_names:\n","      \n","    for j in data_dir_train.glob(i+'/*.jpg'):\n","        path_list.append(str(j))\n","        lesion_list.append(i)\n","dataframe_dict_original = dict(zip(path_list, lesion_list))\n","original_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\n","original_df"],"metadata":{"id":"0G1qNfQW9vXv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe_dict_original = dict(zip(path_list, lesion_list))\n","original_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\n","original_df"],"metadata":{"id":"gAwzKhrT-Lca"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**7. Class distribution**"],"metadata":{"id":"TXR663UK3ZND"}},{"cell_type":"code","source":["count=[]\n","for i in class_names:\n","    count.append(len(list(data_dir_train.glob(i+'/*.jpg'))))\n","plt.figure(figsize=(25,10))\n","plt.bar(class_names,count)"],"metadata":{"id":"LPXcmq2el532"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["****Which class has the least number of samples?****\n","\n","squamous cell carcinoma has least number of samples.\n","\n","****Which classes dominate the data in terms of the proportionate number of samples?****\n","\n","actinic keratosis and dermatofibroma have proportionate number of classes. melanoma and pigmented benign keratosis have proprtionate number of classes.\n","\n"],"metadata":{"id":"i81cTccm3rf6"}},{"cell_type":"markdown","source":["**8. Handling class imbalances**"],"metadata":{"id":"pPvcxt3R4UOy"}},{"cell_type":"code","source":["class_names"],"metadata":{"id":"sT_jzCaf3kBy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install Augmentor"],"metadata":{"id":"UWPXKNlE5ILJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Add 500 samples per class to make sure that none of the classes are sparse.\n","import Augmentor\n","for i in class_names:\n","    p = Augmentor.Pipeline(\"/content/drive/MyDrive/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train\",save_format='jpg')\n","    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n","    p.sample(500) "],"metadata":{"id":"VGsRUwkh4a_Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Take a look at total count of augmented images\n","data_dir_train1 = pathlib.Path(\"/content/drive/MyDrive/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train/output\")\n","image_count_train1 = len(list(data_dir_train1.glob('*/*.jpg')))\n","print(image_count_train1)"],"metadata":{"id":"kMVf2NPZ446P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in class_names:\n","      \n","    for j in data_dir_train1.glob(i+'/*.jpg'):\n","        path_list.append(str(j))\n","        lesion_list.append(i)\n","dataframe_dict_original = dict(zip(path_list, lesion_list))\n","new_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\n","new_df"],"metadata":{"id":"AUG53Dzj9MJk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Distribution of augmented data after adding new images\n","new_df['Label'].value_counts()"],"metadata":{"id":"wB68TeY--jwp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**9. Model Building & training on the rectified class imbalance data**"],"metadata":{"id":"8dWx218t7Ygm"}},{"cell_type":"code","source":["batch_size = 32\n","img_height = 180\n","img_width = 180"],"metadata":{"id":"4EBuIE8Q7JoM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names"],"metadata":{"id":"-fKFQ7kiUtvy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pathlib\n","data_dir_train1=pathlib.Path(\"/content/drive/MyDrive/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")"],"metadata":{"id":"zc85q0Tj7i9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Create a training dataset\n","image_count_train1 = len(list(data_dir_train1.glob('*/*.jpg')))\n","print(image_count_train1)"],"metadata":{"id":"fIDqfLdT7w4Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pathlib\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import os\n","import PIL\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","\n","\n","data_dir_train1=pathlib.Path(\"/content/drive/MyDrive/CNN_assignment/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","  data_dir_train1,\n","  seed=123,\n","  validation_split = 0.2,\n","  subset = \"training\",\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"metadata":{"id":"ITuySpj78AKK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Create a validation dataset\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","  data_dir_train1,\n","  seed=123,\n","  validation_split = 0.2,\n","  subset = 'validation',\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"metadata":{"id":"SsVyyPFI8mm5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create the model "],"metadata":{"id":"exYOPvwcMur1"}},{"cell_type":"code","source":["## Dropout layer if there is an evidence of overfitting\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","num_classes = 9\n","model = Sequential([ \n","                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n","      \n","])\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu', input_shape = (180, 180, 32)))\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","\n","model.add(Flatten())\n","model.add(Dense(num_classes, activation = \"softmax\"))"],"metadata":{"id":"w3N3_WCw82A3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compile the model "],"metadata":{"id":"ETS-0-Q5M7wV"}},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"metadata":{"id":"opGfQV3kNCVi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train the model"],"metadata":{"id":"frxVODheNGh8"}},{"cell_type":"code","source":["## Train the model for ~30 epochs\n","epochs =30\n","history = model.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs\n",")"],"metadata":{"id":"6COJh5-uNDxy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Visualize the model results\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"metadata":{"id":"f76xdBeDNT-R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["****Write your findings after the model fit, see if the issues are resolved or not?****"],"metadata":{"id":"3VRiYp6pTQkM"}},{"cell_type":"code","source":[],"metadata":{"id":"yJalRmPJWlhU"},"execution_count":null,"outputs":[]}]}